name: Deploy Milan to K3s

on:
  push:
    branches:
      - main  # Trigger deployment on changes to the main branch

env:
  CLUSTER_NAME: osd-k8s-cluster
  CLUSTER_ZONE: us-east1

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      - name: Check out repository
        uses: actions/checkout@v3

      - name: Set up kubectl for K3s
        run: |
          echo "Setting up kubectl to use local K3s"
          export KUBEVERSION=$(k3s kubectl version --short)
          export KUBECONFIG=/etc/rancher/k3s/k3s.yaml
          sudo cp /etc/rancher/k3s/k3s.yaml ~/.kube/config
          sudo chown $(id -u):$(id -g) ~/.kube/config

      - name: Create namespace spark-apps
        run: |
          kubectl create namespace spark-apps || echo "Namespace spark-apps already exists"

      - name: Create namespace airflow
        run: |
          kubectl create namespace airflow || echo "Namespace spark-apps already exists"    

      - name: Create namespace Spark Operator
        run: |
          kubectl create namespace spark-operator || echo "Namespace spark-operator already exists"  

      - name: Create namespace trino
        run: |
          kubectl create namespace trino || echo "Namespace trino already exists"    

      - name: Create namespace kafka
        run: |
          kubectl create namespace kafka || echo "Namespace kafka already exists"    

      - name: Create namespace dbt
        run: |
          kubectl create namespace dbt || echo "Namespace dbt already exists" 

      - name: Create namespace superset
        run: |
          kubectl create namespace superset || echo "Namespace superset already exists"            

      - name: Set up Helm
        uses: azure/setup-helm@v3
        with:
          version: 'v3.12.3'  # Specify a version if needed

      - name: Create ClusterRoleBinding
        run: |
          kubectl apply -f spark8s/spark_svc_account.yaml -n spark-apps

      - name: Install Spark Operator
        run: |
          helm upgrade --install osds-release spark8s/spark-operator-1.1.27/spark-operator \
            -n spark-operator \
            --create-namespace \
            --wait \
            --timeout 2m


      - name: Apply Kubernetes manifests
        run: |
          kubectl apply -f spark8s/postgres_hive_ms/postgres_pvc_hive_ms.yaml -n spark-apps
          kubectl apply -f spark8s/postgres_hive_ms/postgres_secret_hive_ms.yaml -n spark-apps
          kubectl apply -f spark8s/postgres_hive_ms/postgres_stateful_hive_ms.yaml -n spark-apps

      - name: Apply Hive Metastore Configurations
        run: |
          kubectl apply -f spark8s/hive-metastore/hive-metastore-cgf.yaml -n spark-apps
          kubectl apply -f spark8s/hive-metastore/hive-metastore.yaml -n spark-apps
          kubectl apply -f spark8s/hive-metastore/hive-metastore-svc.yaml -n spark-apps
          kubectl apply -f spark8s/hive-metastore/hive-schema.yaml -n spark-apps    

      - name: Add Trino Helm repository
        run: |
          helm repo add trino https://trinodb.github.io/charts
          helm repo update

      - name: Install Spark Thrift Server
        run: |
          kubectl apply -f spark8s/spark-thriftserver.yaml -n spark-apps           

      - name: Install Trino
        run: |
          helm upgrade --install --values trino/values.yaml trino trino/trino -n trino    

      - name: Deploy Airflow PostgreSQL
        run: |
          kubectl apply -f airflow_k8s/postgres_airflow/postgres_secret_airflow.yaml -n airflow
          kubectl apply -f airflow_k8s/postgres_airflow/postgres_pvc_airflow.yaml -n airflow
          kubectl apply -f airflow_k8s/postgres_airflow/postgres_stateful_airflow.yaml -n airflow

      - name: Create Airflow secrets
        run: |
          kubectl create secret generic airflow-postgres \
            --from-literal=connection=postgresql://airflow:airflowpass@postgres-airflow:5432/airflow_metastore \
            -n airflow || echo "Secret airflow-postgres already exists"
          
          
          kubectl create secret generic osds-webserver-secret \
            --from-literal="webserver-secret-key=$(python3 -c 'import secrets; print(secrets.token_hex(16))')" \
            -n airflow || echo "Secret osds-webserver-secret already exists"


      - name: Deploy Airflow PVC
        run: |
          kubectl apply -f airflow_k8s/airflow-pvc.yaml -n airflow

      - name: Install Airflow
        run: |
          helm repo add apache-airflow https://airflow.apache.org
          helm repo update
          helm upgrade --install airflow apache-airflow/airflow \
            --namespace airflow \
            --values airflow_k8s/airflow-values.yaml \
            --debug \
            --timeout 10m || echo "Airflow Helm release already exists"

      - name: Create Airflow-Spark ClusterRoleBinding
        run: |
          kubectl create clusterrolebinding default-admin \
            --clusterrole cluster-admin \
            --serviceaccount=airflow:airflow-worker \
            --namespace spark-apps || echo "ClusterRoleBinding already exists"

      - name: Install Strimzi Kafka Operator
        run: |
          helm repo add strimzi https://strimzi.io/charts/
          helm repo update
          helm upgrade --install strimzi strimzi/strimzi-kafka-operator \
            --namespace kafka \
            --wait || echo "Strimzi Helm release already exists"

      - name: Deploy Kafka Persistent and Service
        run: |
          kubectl apply -f kafka/kafka-persistent-single.yaml -n kafka
          kubectl apply -f kafka/kafka-svc.yaml -n kafka

      - name: Create dbt ServiceAccount and ClusterRoleBinding
        run: |
          kubectl create serviceaccount dbt -n dbt || echo "ServiceAccount dbt already exists"
          kubectl create clusterrolebinding dbt-role-binding \
            --clusterrole=edit \
            --serviceaccount=dbt:dbt \
            --namespace=dbt || echo "ClusterRoleBinding dbt-role-binding already exists"

      - name: Add Superset Helm repository
        run: |
          helm repo add superset https://apache.github.io/superset
          helm repo update

      - name: Install Superset
        run: |
          helm upgrade --install --values superset/superset-values.yaml \
            superset superset/superset -n superset --wait || echo "Superset Helm release already exists"

      - name: Delete Hive Schema Pod
        run: |
          kubectl delete -f spark8s/hive-metastore/hive-schema.yaml -n spark-apps