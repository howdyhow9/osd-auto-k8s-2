name: Deploy PostgreSQL to GKE

on:
  push:
    branches:
      - main  # Trigger deployment on changes to the main branch

env:
  CLUSTER_NAME: osd-k8s-cluster
  CLUSTER_ZONE: us-east1
  USER_EMAIL: gvsbharish@gmail.com

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      - name: Check out repository
        uses: actions/checkout@v3

      - name: Google Auth
        id: auth
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ secrets.GCP_PROJECT_ID }}

      - name: Install GKE Auth Plugin
        run: |
          echo "deb [signed-by=/usr/share/keyrings/cloud.google.gpg] https://packages.cloud.google.com/apt cloud-sdk main" | sudo tee -a /etc/apt/sources.list.d/google-cloud-sdk.list
          curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key --keyring /usr/share/keyrings/cloud.google.gpg add -
          sudo apt-get update
          sudo apt-get install -y google-cloud-sdk-gke-gcloud-auth-plugin

      - name: Configure kubectl
        run: |
          gcloud container clusters get-credentials ${{ env.CLUSTER_NAME }} \
            --zone ${{ env.CLUSTER_ZONE }} \
            --project ${{ secrets.GCP_PROJECT_ID }} 

      - name: Create namespace spark-apps
        run: |
          kubectl create namespace spark-apps || echo "Namespace spark-apps already exists"

      - name: Create namespace airflow
        run: |
          kubectl create namespace airflow || echo "Namespace spark-apps already exists"    

      - name: Create namespace Spark Operator
        run: |
          kubectl create namespace spark-operator || echo "Namespace spark-operator already exists"  

      - name: Create namespace trino
        run: |
          kubectl create namespace trino || echo "Namespace trino already exists"    

      - name: Create namespace kafka
        run: |
          kubectl create namespace kafka || echo "Namespace kafka already exists"    

      - name: Set up Helm
        uses: azure/setup-helm@v3
        with:
          version: 'v3.12.3'  # Specify a version if needed

      - name: Create ClusterRoleBinding
        run: |
          kubectl apply -f spark8s/spark_svc_account.yaml -n spark-apps

      - name: Install Spark Operator
        run: |
          helm upgrade --install osds-release spark8s/spark-operator-1.1.27/spark-operator \
            -n spark-operator \
            --create-namespace \
            --wait \
            --timeout 2m
      

      - name: Apply Kubernetes manifests
        run: |
          kubectl apply -f spark8s/postgres_hive_ms/postgres_pvc_hive_ms.yaml -n spark-apps
          kubectl apply -f spark8s/postgres_hive_ms/postgres_secret_hive_ms.yaml -n spark-apps
          kubectl apply -f spark8s/postgres_hive_ms/postgres_stateful_hive_ms.yaml -n spark-apps

      - name: Apply Hive Metastore Configurations
        run: |
          kubectl apply -f spark8s/hive-metastore/hive-metastore-cgf.yaml -n spark-apps
          kubectl apply -f spark8s/hive-metastore/hive-metastore.yaml -n spark-apps
          kubectl apply -f spark8s/hive-metastore/hive-metastore-svc.yaml -n spark-apps
          kubectl apply -f spark8s/hive-metastore/hive-schema.yaml -n spark-apps    

      - name: Add Trino Helm repository
        run: |
          helm repo add trino https://trinodb.github.io/charts
          helm repo update

      - name: Install Trino
        run: |
          helm upgrade --install --values trino/values.yaml trino trino/trino -n trino    

      - name: Deploy Airflow PostgreSQL
        run: |
          kubectl apply -f airflow_k8s/postgres_airflow/postgres_secret_airflow.yaml -n airflow
          kubectl apply -f airflow_k8s/postgres_airflow/postgres_pvc_airflow.yaml -n airflow
          kubectl apply -f airflow_k8s/postgres_airflow/postgres_stateful_airflow.yaml -n airflow

      - name: Create Airflow secrets
        run: |
          kubectl create secret generic airflow-postgres \
            --from-literal=connection=postgresql://airflow:airflowpass@postgres-airflow:5432/airflow_metastore \
            -n airflow || echo "Secret airflow-postgres already exists"

          
          kubectl create secret generic osds-webserver-secret \
            --from-literal="webserver-secret-key=$(python3 -c 'import secrets; print(secrets.token_hex(16))')" \
            -n airflow || echo "Secret osds-webserver-secret already exists"
        

      - name: Deploy Airflow PVC
        run: |
          kubectl apply -f airflow_k8s/airflow-pvc.yaml -n airflow

      - name: Install Airflow
        run: |
          helm repo add apache-airflow https://airflow.apache.org
          helm repo update
          helm upgrade --install airflow apache-airflow/airflow \
            --namespace airflow \
            --values airflow_k8s/airflow-values.yaml \
            --debug \
            --timeout 10m

      - name: Create Airflow-Spark ClusterRoleBinding
        run: |
          kubectl create clusterrolebinding default-admin \
            --clusterrole cluster-admin \
            --serviceaccount=airflow:airflow-worker \
            --namespace spark-apps || echo "ClusterRoleBinding already exists"
          
      - name: Install Strimzi Kafka Operator
        run: |
          helm repo add strimzi https://strimzi.io/charts/
          helm repo update
          helm install strimzi strimzi/strimzi-kafka-operator -n kafka
          
      - name: Deploy Kafka Persistent and Service
        run: |
          kubectl apply -f kafka/kafka-persistent-single.yaml -n kafka
          kubectl apply -f kafka/kafka-svc.yaml -n kafka